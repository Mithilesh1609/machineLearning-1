{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MIzKEzRiLSik"
      },
      "source": [
        "## Download Necessary Packages üìö"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oLPpG5AqLSjP",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,mean_absolute_error"
      ],
      "execution_count": 1,
      "outputs": []
    },


    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CtStujivLSja"
      },
      "source": [
        "## Load Data\n",
        "- We use pandas üêº library to load our data.   \n",
        "- Pandas loads the data into dataframes and facilitates us to analyse the data.   \n",
        "- Learn more about it [here](https://www.tutorialspoint.com/python_data_science/python_pandas.htm) ü§ì"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pVmiwlWwLSjc",
        "colab": {}
      },
      "source": [
        "all_data_path = \"E:/data_science/predict_chess_aicrowd/train_chess_AIcrowd.csv\" #path where data is stored"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wtovJktkLSjn",
        "colab": {}
      },
      "source": [
        "all_data = pd.read_csv(all_data_path) #load data in dataframe using pandas"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CXJ1T6LKLSj0"
      },
      "source": [
        "## Visualize the data üëÄ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dd_HoUSTLSj1",
        "colab": {}
      },
      "source": [
        "all_data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   0  1  2  3  4  5   6\n0  3  1  8  2  6  4  14\n1  2  2  7  7  6  2  14\n2  3  1  3  3  7  7  14\n3  4  1  8  2  1  1   4\n4  3  1  1  5  5  3  13",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>1</td>\n      <td>8</td>\n      <td>2</td>\n      <td>6</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>7</td>\n      <td>7</td>\n      <td>6</td>\n      <td>2</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>7</td>\n      <td>7</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>8</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>3</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "826lfFjlLSkI"
      },
      "source": [
        "We can see the dataset contains 7 columns,where columns 1-6 denotes the position of white king, white rook and black king respectively and the last column tells the optimal depth-of-win for White in 0 to 16 moves and -1 for draw."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dQPFAcR6LSkJ"
      },
      "source": [
        "## Split Data into Train and Validation üî™\n",
        "-  The next step is to think of a way to test how well our model is performing. we cannot use the test data given as it does not contain the data labels for us to verify.    \n",
        "- The workaround this is to split the given training data into training and validation. Typically validation sets give us an idea of how our model will perform on unforeseen data. it is like holding back a chunk of data while training our model and then using it to for the purpose of testing. it is a standard way to fine-tune hyperparameters in a model.    \n",
        "- There are multiple ways to split a dataset into validation and training sets. following are two popular ways to go about it, [k-fold](https://machinelearningmastery.com/k-fold-cross-validation/), [leave one out](https://en.wikipedia.org/wiki/Cross-validation_statistics). üßê\n",
        "- Validation sets are also used to avoid your model from [overfitting](https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/) on the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uJshdqn8LSkL",
        "colab": {}
      },
      "source": [
        "X_train, X_val= train_test_split(all_data, test_size=0.15, random_state=42) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x7XFMqLCLSkf"
      },
      "source": [
        "- We have decided to split the data with 20 % as validation and 80 % as training.  \n",
        "- To learn more about the train_test_split function [click here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). üßê  \n",
        "- This is of course the simplest way to validate your model by simply taking a random chunk of the train set and setting it aside solely for the purpose of testing our train model on unseen data. as mentioned in the previous block, you can experiment üî¨ with and choose more sophisticated techniques and make your model better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SWtxEpQTLSki"
      },
      "source": [
        "- Now, since we have our data splitted into train and validation sets, we need to get the corresponding labels separated from the data.   \n",
        "- with this step we are all set move to the next step with a prepared dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zhMCANvXLSkz",
        "colab": {},
        "tags": []
      },
      "source": [
        "X_train,y_train = X_train.iloc[:,:-1],X_train.iloc[:,-1]\n",
        "X_val,y_val = X_val.iloc[:,:-1],X_val.iloc[:,-1]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BdRUFPGsQsY",
        "colab_type": "text"
      },
      "source": [
        "# TRAINING PHASE üèãÔ∏è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nz9-tVRnLSlF"
      },
      "source": [
        "## Define the Model\n",
        "\n",
        "- We have fixed our data and now we are ready to train our model.   \n",
        "\n",
        "- There are a ton of classifiers to choose from some being [Logistic Regression](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc), [SVM](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47), [Random Forests](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47), [Decision Trees](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052), etc.üßê         \n",
        "\n",
        "- Remember that there are no hard-laid rules here. you can mix and match classifiers, it is advisable to read up on the numerous techniques and choose the best fit for your solution , experimentation is the key.     \n",
        "   \n",
        "- A good model does not depend solely on the classifier but also on the features you choose. So make sure to analyse and understand your data well and move forward with a clear view of the problem at hand.  you can gain important insight from [here](https://towardsdatascience.com/the-5-feature-selection-algorithms-every-data-scientist-need-to-know-3a6b566efd2).üßê         "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X93mmcSpLSlJ",
        "colab": {}
      },
      "source": [
        "#classifier = SVC(gamma='auto',max_iter=500,random_state=None,cache_size=500,C=2)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression,PoissonRegressor,Lasso\n",
        "classifier = LogisticRegression(penalty='elasticnet',solver='saga',l1_ratio=0.6,random_state=1)\n",
        "#classifier = MLPClassifier(alpha=0.001,max_iter=500,activation='relu',solver='adam',batch_size='auto',learning_rate_init=0.001,warm_start=True,epsilon=1e-6,beta_1=0.8,beta_2=0.99,momentum=0.9)\n",
        "#classifier = KNeighborsClassifier(5)\n",
        "#classifier = RandomForestClassifier(n_estimators=70,n_jobs=-1,random_state=101,min_samples_leaf=30,criterion=\"entropy\",max_features=\"log2\",warm_start=True,bootstrap=True)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8GLZ1wkvLSlU"
      },
      "source": [
        "- To start you off, We have used a basic [Support Vector Machines](https://scikit-learn.org/stable/modules/svm.html#classification) classifier here.    \n",
        "- But you can tune parameters and increase the performance. To see the list of parameters visit [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).   \n",
        "- Do keep in mind there exist sophisticated techniques for everything, the key as quoted earlier is to search them and experiment to fit your implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FHfAI5C5LSlV"
      },
      "source": [
        "To read more about other sklearn classifiers visit [here üßê](https://scikit-learn.org/stable/supervised_learning.html). Try and use other classifiers to see how the performance of your model changes. Try using [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) or [MLP](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) and compare how the performance changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rFBYrS_MLSlX"
      },
      "source": [
        "## Train the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vw1oukTXLSla",
        "colab": {}
      },
      "source": [
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "LogisticRegression(l1_ratio=0.6, penalty='elasticnet', random_state=1,\n                   solver='saga')"
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pKgztM3OLSli"
      },
      "source": [
        "Got a warning! Dont worry, its just beacuse the number of iteration is very less(defined in the model in the above cell).Increase the number of iterations and see if the warning vanishes and also see how the performance changes.Do remember increasing iterations also increases the running time.( Hint: max_iter=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjZ9mGY9sQsf",
        "colab_type": "text"
      },
      "source": [
        "# Validation Phase ü§î\n",
        "Wonder how well your model learned! Lets check it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XBwQZ9wkLSli"
      },
      "source": [
        "## Predict on Validation\n",
        "\n",
        "Now we predict using our trained model on the validation set we created and evaluate our model on unforeseen data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t53OxmgoLSlk",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_val)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qA0ZJBUpLSls"
      },
      "source": [
        "## Evaluate the Performance\n",
        "\n",
        "- We have used basic metrics to quantify the performance of our model.  \n",
        "- This is a crucial step, you should reason out the metrics and take hints to improve aspects of your model.\n",
        "- Do read up on the meaning and use of different metrics. there exist more metrics and measures, you should learn to use them correctly with respect to the solution,dataset and other factors. \n",
        "- [F1 score](https://en.wikipedia.org/wiki/F1_score) and [Log Loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html) are the metrics for this challenge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ATJDclSLSlt",
        "colab": {}
      },
      "source": [
        "precision = precision_score(y_val,y_pred,average='micro')\n",
        "recall = recall_score(y_val,y_pred,average='micro')\n",
        "accuracy = accuracy_score(y_val,y_pred)\n",
        "f1 = f1_score(y_val,y_pred,average='macro')\n",
        "mean_abs_error = mean_absolute_error(y_val,y_pred)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_-UzganBLSl0",
        "colab": {},
        "tags": []
      },
      "source": [
        "print(\"Accuracy of the model is :\" ,accuracy)\n",
        "print(\"Recall of the model is :\" ,recall)\n",
        "print(\"Precision of the model is :\" ,precision)\n",
        "print(\"F1 score of the model is :\" ,f1)\n",
        "print(\"mean absolute error is: \",mean_abs_error)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy of the model is : 0.27234927234927236\nRecall of the model is : 0.27234927234927236\nPrecision of the model is : 0.27234927234927236\nF1 score of the model is : 0.20888550180674473\nmean absolute error is:  3.0005940005940004\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cQz8S9kMLSl-"
      },
      "source": [
        "## Load Test Set\n",
        "\n",
        "Load the test data on which final submission is to be made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hGO7Ld8-LSmC",
        "colab": {}
      },
      "source": [
        "final_test_path = \"E:/data_science/predict_chess_aicrowd/test_chess_aicrowd.csv\"\n",
        "final_test = pd.read_csv(final_test_path)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4CYjznLKLSmK"
      },
      "source": [
        "## Predict Test Set\n",
        "Predict on the test set and you are all set to make the submission !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rb-p-xlALSmM",
        "colab": {}
      },
      "source": [
        "submission = classifier.predict(final_test)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n8wB1hHCLSmR"
      },
      "source": [
        "## Save the prediction to csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cANK_raxLSmb",
        "colab": {}
      },
      "source": [
        "submission = pd.DataFrame(submission)\n",
        "submission.to_csv('submission_chess_aicrowd(2).csv',header=['depth'],index=False)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HACAGXJNLSmh"
      },
      "source": [
        "üöß Note :    \n",
        "- Do take a look at the submission format.   \n",
        "- The submission file should contain a header.   \n",
        "- Follow all submission guidelines strictly to avoid inconvenience."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CHESS_baseline.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.7 64-bit",
      "language": "python",
      "name": "python_defaultSpec_1594658569356"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}